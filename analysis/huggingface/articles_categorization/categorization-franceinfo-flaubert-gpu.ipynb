{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"flaubert_franceinfo.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ohiGRgvUtxKMqyVV7eloA0f0UcUHc9hX","authorship_tag":"ABX9TyOrnQRbRMkWaCM/sdDINoF+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wEquy6EYLnIG","executionInfo":{"status":"ok","timestamp":1619775369687,"user_tz":-120,"elapsed":47353,"user":{"displayName":"Emmanuel Coquelin","photoUrl":"","userId":"02840661578834915414"}},"outputId":"e35b4927-202e-45b2-e67a-2d370b52b8b3"},"source":["!pip install pytorch\n","!pip install datasets\n","!pip install transformers\n","!pip install ray[tune]\n","!pip install ray[default]\n","!pip install ray\n","!pip install optuna"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch\n","  Downloading https://files.pythonhosted.org/packages/ee/67/f403d4ae6e9cd74b546ee88cccdb29b8415a9c1b3d80aebeb20c9ea91d96/pytorch-1.0.2.tar.gz\n","Building wheels for collected packages: pytorch\n","  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n","\u001b[?25h  Running setup.py clean for pytorch\n","Failed to build pytorch\n","Installing collected packages: pytorch\n","    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-9stont4w/pytorch/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-9stont4w/pytorch/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-m7c2x3wn/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n","Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/4f/8ef6e4df6e92fc02da620ccfac249112619e5c21273a836958160d6e96fb/datasets-1.6.1-py3-none-any.whl (220kB)\n","\u001b[K     |████████████████████████████████| 225kB 15.8MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n","Collecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n","\u001b[K     |████████████████████████████████| 112kB 25.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Collecting huggingface-hub<0.1.0\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 27.5MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: fsspec, huggingface-hub, xxhash, datasets\n","Successfully installed datasets-1.6.1 fsspec-2021.4.0 huggingface-hub-0.0.8 xxhash-2.0.2\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 12.3MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 51.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n","Collecting ray[tune]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/d0/33b6f8789cec27ac07e33de987eef9430b211c7d8284437371e45d37bbd5/ray-1.3.0-cp37-cp37m-manylinux2014_x86_64.whl (49.7MB)\n","\u001b[K     |████████████████████████████████| 49.7MB 136kB/s \n","\u001b[?25hCollecting aiohttp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 47.4MB/s \n","\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.2)\n","Collecting gpustat\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n","\u001b[?25hCollecting py-spy>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/a6/52515fe345fad06a567feb0ee3841bface31f00e1e0dcd401aa16b3fc648/py_spy-0.3.5-py2.py3-none-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 45.0MB/s \n","\u001b[?25hCollecting aiohttp-cors\n","  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.32.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.10.1)\n","Collecting opencensus\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/d6/b952f11b29c3a0cbec5620de3c4260cecd8c4329d83e91587edb48691e15/opencensus-0.7.12-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 55.8MB/s \n","\u001b[?25hCollecting aioredis\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n","\u001b[?25hCollecting protobuf>=3.15.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/4e/de63de3cd9a83d3c1753a4566b11fc9d90b845f2448a132cfd36d3cb3cd1/protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 42.0MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.6.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.0.12)\n","Collecting redis>=3.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n","\u001b[?25hRequirement already satisfied: pandas; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.1.5)\n","Collecting tensorboardX; extra == \"tune\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n","\u001b[K     |████████████████████████████████| 122kB 55.2MB/s \n","\u001b[?25hRequirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n","Collecting yarl<2.0,>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n","\u001b[K     |████████████████████████████████| 296kB 53.2MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (20.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n","Collecting async-timeout<4.0,>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n","Collecting multidict<7.0,>=4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n","\u001b[K     |████████████████████████████████| 143kB 56.8MB/s \n","\u001b[?25hRequirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.0.4)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (1.15.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (5.4.8)\n","Collecting blessings>=1.6\n","  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]) (1.26.3)\n","Collecting opencensus-context==0.1.2\n","  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n","Collecting hiredis\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/33/290cea35b09c80b4634773ad5572a8030a87b5d39736719f698f521d2a13/hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (56.0.0)\n","Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.28.1)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.53.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (20.9)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.2.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (2.4.7)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n","Building wheels for collected packages: gpustat\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-0.6.0-cp37-none-any.whl size=12621 sha256=1f68ac3d5e0ab0015ada793750a880cc3d83761e91cce29bc50ae56e82bc7c15\n","  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n","Successfully built gpustat\n","Installing collected packages: multidict, yarl, async-timeout, aiohttp, blessings, gpustat, py-spy, aiohttp-cors, colorama, opencensus-context, opencensus, hiredis, aioredis, protobuf, redis, tensorboardX, ray\n","  Found existing installation: protobuf 3.12.4\n","    Uninstalling protobuf-3.12.4:\n","      Successfully uninstalled protobuf-3.12.4\n","Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 gpustat-0.6.0 hiredis-2.0.0 multidict-5.1.0 opencensus-0.7.12 opencensus-context-0.1.2 protobuf-3.15.8 py-spy-0.3.5 ray-1.3.0 redis-3.5.3 tensorboardX-2.2 yarl-1.6.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (7.1.2)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.32.0)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.15.8)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.5.3)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.7.12)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.4.4)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.0.12)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.6.0)\n","Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.7.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.7.4.post0)\n","Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.6.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.13)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.10.1)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.2)\n","Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.1)\n","Collecting colorful; extra == \"default\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n","\u001b[K     |████████████████████████████████| 204kB 12.4MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[default]) (1.15.0)\n","Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (0.1.2)\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (1.26.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (2020.12.5)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]) (3.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]) (20.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]) (3.7.4.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]) (5.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]) (1.6.3)\n","Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[default]) (1.7)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[default]) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[default]) (5.4.8)\n","Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray[default]) (2.0.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (2018.9)\n","Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (1.28.1)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (56.0.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (1.53.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (20.9)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (4.2.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (2.4.7)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[default]) (0.4.8)\n","Installing collected packages: colorful\n","Successfully installed colorful-0.5.4\n","Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.32.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray) (3.5.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.4.post0)\n","Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray) (0.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray) (0.10.1)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.15.8)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n","Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.0.12)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray) (0.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.12)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray) (0.3.5)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.7.4.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (20.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (1.6.3)\n","Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.0.4)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.0.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (5.1.0)\n","Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (2.0.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (7.352.0)\n","Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (1.7)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (5.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (1.26.3)\n","Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (0.1.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.53.0)\n","Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.28.1)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (20.9)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (56.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.7.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n","Collecting optuna\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/21/d13081805e1e1afc71f5bb743ece324c8bd576237c51b899ecb38a717502/optuna-2.7.0-py3-none-any.whl (293kB)\n","\u001b[K     |████████████████████████████████| 296kB 12.8MB/s \n","\u001b[?25hCollecting alembic\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/a4/97eb6273839655cac14947986fa7a5935350fcfd4fff872e9654264c82d8/alembic-1.5.8-py2.py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 26.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n","Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n","Collecting colorlog\n","  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.7)\n","Collecting cliff\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n","Collecting cmaes>=0.8.2\n","  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n","Collecting python-editor>=0.3\n","  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n","Collecting Mako\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (3.10.1)\n","Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n","Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n","Collecting cmd2>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n","\u001b[K     |████████████████████████████████| 143kB 27.9MB/s \n","\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 30.4MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n","Collecting stevedore>=2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n","Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n","Collecting pyperclip>=1.6\n","  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=9c80f4015205656c000cea7b08c989742295f78ec81aae6157e6aac2f7db66c6\n","  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n","Successfully built pyperclip\n","Installing collected packages: python-editor, Mako, alembic, colorlog, pyperclip, cmd2, pbr, stevedore, cliff, cmaes, optuna\n","Successfully installed Mako-1.1.4 alembic-1.5.8 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorlog-5.0.1 optuna-2.7.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJ2hwmeZr5tn","executionInfo":{"status":"ok","timestamp":1619771516029,"user_tz":-120,"elapsed":479,"user":{"displayName":"Emmanuel Coquelin","photoUrl":"","userId":"02840661578834915414"}},"outputId":"8379c40b-9b97-416e-c1fd-8f643d021e06"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"id":"Tg3n72O6LM48","executionInfo":{"status":"ok","timestamp":1619858535040,"user_tz":-120,"elapsed":82066467,"user":{"displayName":"Emmanuel Coquelin","photoUrl":"","userId":"02840661578834915414"}},"outputId":"598ba54b-2882-44b9-fe57-445f6b07deab"},"source":["import logging\n","\n","from ray import tune\n","from sklearn import metrics\n","import datasets\n","import numpy as np\n","import torch\n","from datasets import load_dataset, DatasetDict, ClassLabel\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import EarlyStoppingCallback\n","from transformers import TrainingArguments, Trainer, FlaubertTokenizer, FlaubertForSequenceClassification, \\\n","    IntervalStrategy\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","\n","# Read data\n","from transformers.trainer_utils import HPSearchBackend\n","\n","raw_train_ds, raw_test_ds, raw_validation_ds = None, None, None\n","\n","\n","\n","# Graph styling\n","# better display of review text in dataframes\n","pd.set_option('display.max_colwidth', None)\n","\n","sns.set(style=\"whitegrid\")\n","\n","categories_list = [\n","#'alpes-maritimes',\n","#'hautes-alpes',\n","#'festival-avignon',\n","#'bouches-du-rhone',\n","# 'en-image',\n","#'bac-2014',\n","#'brevet',\n","# 'home',\n","# 'vrai-ou-fake',\n","# 'choix',\n","# 'partenariats',\n","#'festival-de-cannes',\n","#'bac',\n","# 'animaux',\n","# 'internet',\n","# 'sciences',\n","# 'replay-magazine',\n","#'elections',\n","# 'decouverte',\n","'sports',\n","# 'replay-jt',\n","'france',\n","#'meteo',\n","'societe',\n","'faits-divers',\n","'sciences-technologie',\n","'politique',\n","'sante',\n","'culture',\n","# 'replay-radio',\n","'economie',\n","'monde'\n","]\n","\n","# Define pretrained tokenizer and model\n","model_name = \"flaubert/flaubert_base_cased\"\n","tokenizer = FlaubertTokenizer.from_pretrained(model_name)\n","\n","# Define Trainer parameters\n","\n","dataset_path = \"drive/MyDrive/Lab/Newsify/all-articles.json\"\n","model_path = \"drive/MyDrive/Lab/Newsify/output/trainer-flaubert-small\"\n","# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","def CountFrequency(list):\n","\n","    # Creating an empty dictionary\n","    freq = {}\n","    for item in list:\n","        if (item in freq):\n","            freq[item] += 1\n","        else:\n","            freq[item] = 1\n","\n","    return freq\n","\n","def merge_categories(article):\n","    if article['categorie'] in ['alpes-maritimes', 'hautes-alpes', 'bouches-du-rhone', 'bac-2014', 'bac', 'brevet']:\n","        article['categorie'] = 'france'\n","    elif article['categorie'] in ['festival-avignon', 'festival-de-cannes']:\n","        article['categorie'] = 'culture'\n","    elif article['categorie'] in ['elections']:\n","        article['categorie'] = 'politique'\n","    elif article['categorie'] in ['sciences', 'animaux', 'internet']:\n","        article['categorie'] = 'sciences-technologie'\n","\n","    return article\n","\n","def analyze_data():\n","    dataset = load_dataset('json', data_files=dataset_path)['train']\n","    before_filter_length = len(dataset)\n","    dataset_filtered = dataset.filter(lambda article: article['article'] is not None)\n","\n","    filtered_length = before_filter_length - len(dataset_filtered)\n","    print(\"{} articles with no data ({:.2f} % of total data removed)\".format(\n","        filtered_length,\n","        100 * filtered_length / before_filter_length\n","    ))\n","\n","    dataset_filtered = dataset_filtered.map(merge_categories)\n","    print(\"Merged articles categories\")\n","\n","    before_filter_length = len(dataset_filtered)\n","    dataset_filtered = dataset_filtered.filter(lambda article: article['categorie'] in categories_list )\n","    filtered_length = before_filter_length - len(dataset_filtered)\n","    print(\"{} articles with an invalid category ({:.2f} % of total data removed)\".format(\n","        filtered_length,\n","        100 * filtered_length / before_filter_length\n","    ))\n","\n","    # Filter coronavirus\n","    before_filter_length = len(dataset_filtered)\n","    dataset_filtered = dataset_filtered.filter(lambda article: article['categorie'] != \"sante\" or \"coronavirus\" not in article['url'])\n","    filtered_length = before_filter_length - len(dataset_filtered)\n","    print(\"{} articles with coronavirus subject ({:.2f} % of total data removed)\".format(\n","        filtered_length,\n","        100 * filtered_length / before_filter_length\n","    ))\n","\n","\n","    WORDS_MIN_THRESHOLD = 20\n","    WORDS_MAX_THRESHOLD = 600\n","    before_filter_length = len(dataset_filtered)\n","    dataset_filtered = dataset_filtered.filter(lambda article: article['mots'] < WORDS_MAX_THRESHOLD and article['mots'] > WORDS_MIN_THRESHOLD )\n","    filtered_length = before_filter_length - len(dataset_filtered)\n","    print(\"{} articles with words < {} or words > {} ({:.2f} % of total data removed)\".format(\n","        filtered_length,\n","        WORDS_MIN_THRESHOLD,\n","        WORDS_MAX_THRESHOLD,\n","        100 * filtered_length / before_filter_length\n","    ))\n","\n","    LENGTH_MAX_THRESHOLD = 3000\n","    before_filter_length = len(dataset_filtered)\n","    dataset_filtered = dataset_filtered.filter(lambda article: len(article['article']) <= LENGTH_MAX_THRESHOLD )\n","    filtered_length = before_filter_length - len(dataset_filtered)\n","    print(\"{} articles with length > {} ({:.2f} % of total data removed)\".format(\n","        filtered_length,\n","        LENGTH_MAX_THRESHOLD,\n","        100 * filtered_length / before_filter_length\n","    ))\n","\n","    print(\"{} articles in dataset\".format(len(dataset_filtered)))\n","\n","    def plot_length_repartition(dataset):\n","        articles_length = []\n","        for article in dataset:\n","            articles_length.append(len(article['article']))\n","\n","        plt.figure(figsize=(10, 5))\n","        ax = sns.distplot(articles_length, bins=150, kde=False, hist_kws=dict(alpha=0.8))\n","        ax.set(xlabel='Article Length')\n","\n","        # Finalize the plot\n","        sns.despine(bottom=True)\n","        plt.tight_layout(h_pad=2)\n","\n","        # Saving plot\n","        fig = ax.get_figure()\n","        fig.savefig('output/articles_length.png', dpi=200)\n","        return\n","\n","    def plot_word_count_repartition(dataset):\n","        words_count = []\n","        for article in dataset:\n","            if article['article'] is not None:\n","                words_count.append(article['mots'])\n","\n","        plt.figure(figsize=(10, 5))\n","        ax = sns.distplot(words_count, bins=150, kde=False, hist_kws=dict(alpha=0.8))\n","        ax.set(xlabel='Words Count')\n","\n","        # Finalize the plot\n","        sns.despine(bottom=True)\n","        plt.tight_layout(h_pad=2)\n","\n","        # Saving plot\n","        fig = ax.get_figure()\n","        fig.savefig('output/articles_words.png', dpi=200)\n","        return\n","\n","    def plot_count_by_categories(dataset):\n","\n","        articles_per_categorie = CountFrequency(dataset['categorie'])\n","        plt.figure(figsize=(8, 5))\n","        articles_per_categorie = dict(sorted(articles_per_categorie.items(), key=lambda item: item[1]))\n","        for key, value in articles_per_categorie.items():\n","            print(\"{} : {}\".format(key, value))\n","\n","        ax = sns.barplot(y=list(articles_per_categorie.keys()), x=list(articles_per_categorie.values()))\n","        ax.set(xlabel='', ylabel='Categories')\n","\n","        # Finalize the plot\n","        sns.despine(bottom=True)\n","        plt.tight_layout(h_pad=2)\n","\n","        # Saving plot\n","        fig = ax.get_figure()\n","        fig.savefig('output/articles_per_categories.png', dpi=200)\n","        return\n","\n","    def plot_count_by_year(dataset):\n","\n","        years = map(lambda dateString : pd.to_datetime(dateString).year, dataset['date'])\n","        articles_per_year = CountFrequency(years)\n","        for key, value in articles_per_year.items():\n","            print(\"{} : {}\".format(key, value))\n","        plt.figure(figsize=(8, 5))\n","        ax = sns.barplot(list(articles_per_year.keys()), list(articles_per_year.values()))\n","        ax.set(xlabel='Year', ylabel='')\n","\n","        # Finalize the plot\n","        sns.despine(bottom=True)\n","        plt.tight_layout(h_pad=2)\n","\n","        # Saving plot\n","        fig = ax.get_figure()\n","        fig.savefig('output/articles_per_year.png', dpi=200)\n","        return\n","\n","    # plot_length_repartition(dataset_filtered)\n","    # plot_word_count_repartition(dataset_filtered)\n","    # plot_count_by_year(dataset_filtered)\n","    # plot_count_by_categories(dataset_filtered)\n","\n","    replays = dataset_filtered.filter(lambda article: article['categorie'] == 'replay-radio')\n","    replays = replays.shuffle(seed=42).select([0, 10, 20, 30, 40, 50])\n","    replays.map(lambda example: print(example))\n","\n","    # dataset is already `map`'d and already has `set_format`\n","    # 90% train, 10% test + validation\n","    train_testvalid = dataset_filtered.train_test_split(test_size=0.1)\n","    # Split the 10% test + valid in half test, half valid\n","    test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n","    # gather everyone if you want to have a single DatasetDict\n","    datasets = DatasetDict({\n","        \"train\": train_testvalid[\"train\"],\n","        \"test\": test_valid[\"test\"],\n","        \"valid\": test_valid[\"train\"]})\n","\n","    datasets.save_to_disk('output/processed-dataset')\n","\n","\n","def preprocess_data():\n","    global raw_test_ds, raw_validation_ds, raw_train_ds\n","    labels = ClassLabel(names = categories_list)\n","    logging.info(\"Preprocessing data\")\n","    # ----- 1. Preprocess data -----#\n","    raw_train_ds = datasets.load_from_disk('./output/processed-dataset/train')\n","    raw_validation_ds = datasets.load_from_disk('./output/processed-dataset/valid')\n","\n","    # Preprocess data\n","    X_train = list(raw_train_ds[\"article\"])\n","    y_train = labels.str2int(raw_train_ds[\"categorie\"])\n","    X_val = list(raw_validation_ds[\"article\"])\n","    y_val = labels.str2int(raw_validation_ds[\"categorie\"])\n","    X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","    X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","\n","\n","\n","\n","    train_dataset = Dataset(X_train_tokenized, y_train)\n","    val_dataset = Dataset(X_val_tokenized, y_val)\n","\n","    logging.info(\"Data preprocessed\")\n","    return train_dataset, val_dataset\n","\n","def model_init():\n","    return FlaubertForSequenceClassification.from_pretrained(model_name, num_labels=len(categories_list))\n","\n","def create_model(train_dataset, val_dataset):\n","    def compute_metrics(p):\n","        pred, labels = p\n","        pred = np.argmax(pred, axis=1)\n","\n","        accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","        recall = recall_score(y_true=labels, y_pred=pred, average=\"micro\")\n","        precision = precision_score(y_true=labels, y_pred=pred, average=\"micro\")\n","        f1 = f1_score(y_true=labels, y_pred=pred, average=\"micro\")\n","\n","        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","    # Define Trainer\n","    args = TrainingArguments(\n","        output_dir=\"output\",\n","        learning_rate=1e-5,\n","        # tpu_num_cores=8,\n","        # adam_epsilon=1e-8,\n","        evaluation_strategy=IntervalStrategy.EPOCH,\n","        per_device_train_batch_size=8,\n","        per_device_eval_batch_size=8,\n","        num_train_epochs=3,\n","        weight_decay=0.07,\n","        metric_for_best_model=\"accuracy\",\n","        load_best_model_at_end=True\n","    )\n","    trainer = Trainer(\n","        model_init=model_init,\n","        args=args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics,\n","\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n","    )\n","    return trainer\n","\n","def hyperparameter_space(trial):\n","\n","    return {\n","        \"per_device_train_batch_size\": tune.choice([24, 48, 64]),\n","        'learning_rate': tune.uniform(1e-5, 5e-5),\n","        'seed': tune.choice(range(1, 50)),\n","        'weight_decay': tune.uniform(0.0, 0.3),\n","        'num_train_epochs': tune.choice([2, 3, 4, 5]),\n","    }\n","\n","def train_model(trainer: Trainer):\n","\n","    # best_run = trainer.hyperparameter_search(n_trials=5,\n","    #                                         #  hp_space=hyperparameter_space,\n","    #                                          direction=\"maximize\", \n","    #                                         #  backend=HPSearchBackend.RAY,\n","    #                                         #  resources_per_trial={\"cpu\": 1, \"gpu\": 1}\n","    #                                          )\n","    # for n, v in best_run.hyperparameters.items():\n","    #     setattr(trainer.args, n, v)\n","    return trainer.train()\n","\n","def evaluate_model(trainer: Trainer):\n","    trainer.evaluate()\n","\n","def save_model(trainer: Trainer):\n","    trainer.save_model(model_path)\n","\n","def load_model():\n","    # Load trained model\n","\n","    model = FlaubertForSequenceClassification.from_pretrained(model_path, num_labels=len(categories_list))\n","\n","    # Define test trainer\n","    return Trainer(model)\n","\n","def main():\n","    # analyze_data()\n","    train_dataset, val_dataset = preprocess_data()\n","    trainer = create_model(train_dataset, val_dataset)\n","    train_model(trainer)\n","    evaluate_model(trainer)\n","    save_model(trainer)\n","    saved_model = load_model()\n","    # model_analysis(saved_model)\n","\n","\n","    raw_test_ds = datasets.load_from_disk('./output/processed-dataset/test')\n","\n","\n","    labels = ClassLabel(names=categories_list)\n","    X_val = list(raw_test_ds[\"article\"])\n","    y_val = labels.str2int(raw_test_ds[\"categorie\"])\n","    X_test_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","    # Make prediction\n","    raw_pred, _, _ = saved_model.predict(Dataset(X_test_tokenized))\n","    #\n","    # # Preprocess raw predictions\n","    y_pred = np.argmax(raw_pred, axis=1)\n","    test_acc  = metrics.accuracy_score(y_val, y_pred)\n","    print(\"Test accuracy : {}\".format(test_acc))\n","\n","    sport = \"\\nRafael Nadal se disait \\u00ab\\u00a0pr\\u00eat et en confiance\\u00a0\\u00bb avant d\\u2019attaquer la saison sur terre battue.\\u00a0Et nous, bah, on plaignait d\\u2019avance ses adversaires. Et pourtant\\u00a0:\\u00a0ce vendredi Andrey Rublev (8e mondial) a assomm\\u00e9 l\\u2019Espagnol (3e) 6-2, 4-6, 6-2 en 2h32, en quarts de finale du Masters 1000 de \\r\\nMonte-Carlo. Rublev retrouvera Casper Ruud (27e) dans le dernier carr\\u00e9.\\r\\n\\r\\nNadal\\u00a0ne s\\u2019est pas montr\\u00e9 au sommet de son art, commettant de nombreuses fautes, mais il a souvent \\u00e9t\\u00e9 pris par les coups violents et pr\\u00e9cis du Russe. Ce dernier jouera sa deuxi\\u00e8me demi-finale de Masters 1000 apr\\u00e8s celle de Miami au d\\u00e9but du mois.\\r\\n\\r\\nMedvedev, Djokovic et Nadal out\\r\\n\\r\\n\\u00ab\\u00a0Pour lui, \\u00e7a doit \\u00eatre incroyablement difficile de jouer avec cette pression de devoir toujours gagner. Je suis sous le choc de voir le niveau auquel il peut \\u00e9voluer malgr\\u00e9 cette pression. C\\u2019est beaucoup plus facile de jouer quand on n\\u2019a rien \\u00e0 perdre\\u00a0\\u00bb, a comment\\u00e9 Rublev.\\r\\n\\r\\nApr\\u00e8s l\\u2019exclusion du N.2 mondial Daniil Medvedev pour un test positif au Covid-19\\u00a0avant le d\\u00e9but du tournoi, puis l\\u2019\\u00e9limination du N.1 Novak Djokovic la veille en 8es de finale, Nadal est la troisi\\u00e8me t\\u00eate d\\u2019affiche \\u00e0 quitter le tournoi mon\\u00e9gasque.\\r\\n\\r\\nL\\u2019Espagnol n\\u2019avait plus jou\\u00e9 depuis l\\u2019Open d\\u2019Australie en f\\u00e9vrier avant de s\\u2019aligner sur le tournoi mon\\u00e9gasque qu\\u2019il a remport\\u00e9 \\u00e0 onze reprises.\\r\\n\\r\\nSportMonte-Carlo\\u00a0: Novak Djokovic balay\\u00e9 en deux manches par Daniel EvansSportMonte-Carlo\\u00a0: \\u00ab\\u00a0J\\u2019en ai rien \\u00e0 branler\\u00a0\\u00bb, Beno\\u00eet Paire en roue libre apr\\u00e8s sa d\\u00e9faite au premier tour\\n\"\n","    divers = \"\\nLe\\u00a0cancer l\\u2019a emport\\u00e9e.\\u00a0L\\u2019actrice britannique Helen McCrory, qui a jou\\u00e9 au cin\\u00e9ma dans Skyfall et Harry Potter, et \\u00e0 la t\\u00e9l\\u00e9vision dans la s\\u00e9rie Peaky Blinders, est morte \\u00e0 l\\u2019\\u00e2ge de 52 ans d\\u2019un cancer, a annonc\\u00e9 ce vendredi son \\u00e9poux Damian Lewis sur Twitter.\\r\\n\\r\\n\\u00ab\\u00a0J\\u2019ai le coeur bris\\u00e9 d\\u2019annoncer que, apr\\u00e8s une bataille h\\u00e9ro\\u00efque contre le cancer, la femme magnifique qu\\u2019est Helen McCrory est morte paisiblement chez elle, au milieu d\\u2019une vague d\\u2019amour de ses amis et de sa famille\\u00a0\\u00bb, a d\\u00e9clar\\u00e9 le com\\u00e9dien dans un court texte sur le r\\u00e9seau social.\\u00a0\\u00ab\\u00a0Elle est morte comme elle a v\\u00e9cu. Sans peur. Dieu que nous l\\u2019aimons et savons la chance que nous avons eue de l\\u2019avoir dans nos vies\\u00a0\\u00bb, a-t-il ajout\\u00e9.\\r\\n\\r\\npic.twitter.com\\/gSx8ib9PY9\\u2014 Damian Lewis (@lewis_damian) April 16, 2021\\n\\nStar de\\u00a0Peaky Blinders\\n\\r\\n\\r\\nApparue pour la premi\\u00e8re fois au cin\\u00e9ma dans un petit r\\u00f4le dans Entretien avec un Vampire\\u00a0apr\\u00e8s avoir commenc\\u00e9 sa carri\\u00e8re \\u00e0 la t\\u00e9l\\u00e9vision, Helen McCrory a notamment incarn\\u00e9 Narcissa Malfoy dans les derniers films de la saga Harry Potter.\\u00a0\\r\\n\\r\\nL\\u2019actrice, qui a \\u00e9galement jou\\u00e9 dans Skyfall\\u00a0de la saga James Bond, incarnait\\u00a0\\u00e0 la perfection le personnage de tante Polly, matriarche du clan Shelby, dans la s\\u00e9rie britannique \\u00e0 succ\\u00e8s Peaky Blinders, qui retrace les aventures d\\u2019une famille de malfrats de Birmingham au d\\u00e9but du 20e\\u00a0si\\u00e8cle.\\u00a0Elle avait \\u00e9pous\\u00e9 \\r\\nDamian Lewis en 2007, avec qui elle a eu deux enfants.\\r\\n\\r\\nPeopleCoronavirus : Devant l\\u2019insistance du casting, le tournage de \\u00ab\\u00a0Peaky Blinders\\u00a0\\u00bb s\\u2019est arr\\u00eat\\u00e9 d\\u00e8s le d\\u00e9but de la pand\\u00e9mie\\n\"\n","    economie = \"\\nL'Europe doit \\u00eatre \\u00ab\\u00a0aux avant-postes\\u00a0\\u00bb de la cr\\u00e9ation d\\u2019une monnaie num\\u00e9rique commune et \\u00ab\\u00a0activement\\u00a0\\u00bb oeuvrer pour que ce nouvel outil de paiement voie le jour, a plaid\\u00e9 vendredi le ministre \\r\\nallemand des Finances, Olaf Scholz.\\r\\n\\r\\n\\u00ab\\u00a0Une Europe souveraine a besoin de solutions de paiement innovantes et comp\\u00e9titives\\u00a0\\u00bb, a d\\u00e9clar\\u00e9 Olaf\\u00a0Scholz en amont d\\u2019une visioconf\\u00e9rence des ministres des Finances de la zone euro (Eurogroupe), qui doit aborder cette question. Pour le ministre social-d\\u00e9mocrate, \\u00ab\\u00a0l\\u2019Europe doit \\u00eatre aux avant-postes sur la question des monnaies digitales de banque centrale et doit activement le faire progresser\\u00a0\\u00bb.\\r\\n\\r\\nLa BCE d\\u00e9cidera cet \\u00e9t\\u00e9\\r\\n\\r\\nAinsi, la premi\\u00e8re \\u00e9conomie de la zone euro  \\u00ab\\u00a0soutiendra de fa\\u00e7on constructive\\u00a0\\u00bb les travaux engag\\u00e9s par la Banque centrale europ\\u00e9enne (BCE) en vue de la possible cr\\u00e9ation d\\u2019un euro digital. \\u00ab\\u00a0Nous ne devons pas \\u00eatre spectateurs\\u00a0\\u00bb de cette \\u00e9volution, a estim\\u00e9 le ministre allemand qui a \\u00e9galement appel\\u00e9 \\u00e0 \\u00ab\\u00a0ne pas se rendre d\\u00e9pendant l\\u00e0 o\\u00f9 la souverainet\\u00e9 des Etats est en jeu\\u00a0\\u00bb.\\r\\n\\r\\nLa BCE d\\u00e9cidera cet \\u00e9t\\u00e9 si elle se lance ou non dans la cr\\u00e9ation d\\u2019un euro num\\u00e9rique, \\u00e0 l\\u2019issue d\\u2019une vaste consultation et d\\u2019\\u00e9tudes engag\\u00e9es ces derniers mois, a indiqu\\u00e9 cette semaine l\\u2019un de ses responsables.\\r\\n\\r\\nPas besoin de compte en banque\\r\\n\\r\\nSelon une enqu\\u00eate publique de l\\u2019institution de Francfort, \\u00e9galement d\\u00e9voil\\u00e9e cette semaine, les particuliers et les professionnels interrog\\u00e9s attendent en premier lieu de la monnaie num\\u00e9rique la confidentialit\\u00e9 (43\\u00a0%), suivie de la s\\u00e9curit\\u00e9 (18\\u00a0%), la capacit\\u00e9 de payer dans la zone euro (11\\u00a0%), l\\u2019absence de frais suppl\\u00e9mentaires (9\\u00a0%) et la possibilit\\u00e9 de payer en dehors de l\\u2019internet (8\\u00a0%).\\r\\n\\r\\nLa question des cryptomonnaies est \\u00e9tudi\\u00e9e de pr\\u00e8s par de nombreux pays, face notamment au projet de monnaie num\\u00e9rique initi\\u00e9 par Facebook, la Libra.\\u00a0Plusieurs banques centrales planchent sur le sujet, la Chine et son projet de crypto-yuan comptant parmi les plus avanc\\u00e9s.\\r\\n\\r\\nLes monnaies num\\u00e9riques sont stock\\u00e9es sur des supports \\u00e9lectroniques, sans avoir besoin de compte en banque, et sont accept\\u00e9es comme moyen de paiement par des entreprises.\\r\\n\\r\\nMondeCoronavirus\\u00a0: Contrairement \\u00e0 une grande partie de l\\u2019Europe, la Suisse all\\u00e8ge ses restrictionsSant\\u00e9Coronavirus : Peut-on s'inspirer des pays en d\\u00e9confinement pour r\\u00e9ussir le n\\u00f4tre ?\\n\"\n","\n","    examples = [sport, divers, economie]\n","    examples_tokenized = tokenizer(examples, padding=True, truncation=True, max_length=512)\n","\n","    raw_pred, _, _ = saved_model.predict(Dataset(examples_tokenized))\n","    y_pred = np.argmax(raw_pred, axis=1)\n","\n","    for pred in labels.int2str(y_pred):\n","        print(\"Categorie : {}\".format(pred))\n","main()\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at flaubert/flaubert_base_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n","- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_base_cased and are newly initialized: ['transformer.position_ids', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at flaubert/flaubert_base_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n","- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_base_cased and are newly initialized: ['transformer.position_ids', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='118212' max='118212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [118212/118212 22:07:30, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.659200</td>\n","      <td>0.643200</td>\n","      <td>0.787301</td>\n","      <td>0.787301</td>\n","      <td>0.787301</td>\n","      <td>0.787301</td>\n","      <td>222.904400</td>\n","      <td>78.567000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.560400</td>\n","      <td>0.635450</td>\n","      <td>0.793411</td>\n","      <td>0.793411</td>\n","      <td>0.793411</td>\n","      <td>0.793411</td>\n","      <td>233.400700</td>\n","      <td>75.034000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.520000</td>\n","      <td>0.636400</td>\n","      <td>0.799977</td>\n","      <td>0.799977</td>\n","      <td>0.799977</td>\n","      <td>0.799977</td>\n","      <td>237.865900</td>\n","      <td>73.626000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='2190' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2190/2190 03:57]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='2191' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2190/2190 03:38]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Test accuracy : 0.7940958145377719\n","Categorie : sports\n","Categorie : culture\n","Categorie : economie\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBLaftcnLaCQ"},"source":["    saved_model = load_model()\n","    examples = [\n","            \"The movie was great!\",\n","            \"The movie was okay.\",\n","            \"The movie was terrible...\",\n","            \"The movie was terrific!\",\n","            \"Le film était pas terrible\",\n","            \"Le film était terrible !\",\n","            \"Le film était terriblement bien\"\n","        ]\n","\n","    x_examples = tokenizer(examples, padding=True, truncation=True, max_length=512)\n","    raw_pred, _, _ = saved_model.predict(Dataset(x_examples))\n","    y_pred = np.argmax(raw_pred, axis=1)\n","    print(y_pred)"],"execution_count":null,"outputs":[]}]}